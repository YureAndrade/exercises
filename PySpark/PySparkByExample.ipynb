{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark by Example"
      ],
      "metadata": {
        "id": "zuWtpoJTVNgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing dependencies and updating"
      ],
      "metadata": {
        "id": "2MnYVm9M00FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get upgrade\n",
        "!pip install pyspark\n",
        "!apt-get autoremove"
      ],
      "metadata": {
        "id": "7Y_W8StBY3HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing Spark context"
      ],
      "metadata": {
        "id": "Xiv_Z6QM0-V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import to_timestamp,col,lit\n",
        "\n",
        "spark = SparkSession \\\n",
        ".builder \\\n",
        ".appName(\"PySpark by Example\") \\\n",
        ".getOrCreate()"
      ],
      "metadata": {
        "id": "WQ2N3OzoY4nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the data"
      ],
      "metadata": {
        "id": "1da9Strn1B-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://data.cityofchicago.org/api/views/ijzp-q8t2/rows.csv?accessType=DOWNLOAD"
      ],
      "metadata": {
        "id": "iQ6ThUqfJsoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the data"
      ],
      "metadata": {
        "id": "0Xx1nBFS1IJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('reported-crimes.csv', header = True).withColumn('Date', to_timestamp(col('Date'), 'MM/dd/yyyy hh:mm:ss a'))"
      ],
      "metadata": {
        "id": "bHNvtP2YHwsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.filter(df.Arrest == 1)"
      ],
      "metadata": {
        "id": "hX_pxZ4aY6Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading auto infered data schema"
      ],
      "metadata": {
        "id": "5wuHQqcO1MZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "sJj2tUqMY6Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing SQL types from PySpark"
      ],
      "metadata": {
        "id": "2GvlWOz01ZM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, BooleanType, DoubleType, IntegerType"
      ],
      "metadata": {
        "id": "xu8nyUacY6FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a schema for dataset"
      ],
      "metadata": {
        "id": "hFZarwW41fGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\n",
        "    ('ID', StringType()),\n",
        "    ('Case Number', StringType()),\n",
        "    ('Date', TimestampType()),\n",
        "    ('Block', StringType()),\n",
        "    ('IUCR', StringType()),\n",
        "    ('Primary Type', StringType()),\n",
        "    ('Description', StringType()),\n",
        "    ('Location Description', StringType()),\n",
        "    ('Arrest', StringType()),\n",
        "    ('Domestic', BooleanType()),\n",
        "    ('Beat', StringType()),\n",
        "    ('District', StringType()),\n",
        "    ('Ward', StringType()),\n",
        "    ('Community Area', StringType()),\n",
        "    ('FBI Code', StringType()),\n",
        "    ('X Coordinate', StringType()),\n",
        "    ('Y Coordinate', StringType()),\n",
        "    ('Year', IntegerType()),\n",
        "    ('Updated On', StringType()),\n",
        "    ('Latitude', DoubleType()),\n",
        "    ('Longitude', DoubleType()),\n",
        "    ('Location', StringType())\n",
        "    \n",
        "]"
      ],
      "metadata": {
        "id": "rNSyBRFHY6CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([StructField (x[0], x[1], True) for x in labels])\n",
        "schema"
      ],
      "metadata": {
        "id": "K-eoccayY5_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the data using the previously schema"
      ],
      "metadata": {
        "id": "feszvoQ71tOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('reported-crimes.csv', schema=schema, header = True).withColumn('Date', to_timestamp(col('Date'), 'MM/dd/yyyy hh:mm:ss a'))"
      ],
      "metadata": {
        "id": "7DopJKpFY57d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "kEyM902YY54a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manipulation rows"
      ],
      "metadata": {
        "id": "1QER51TP2IRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_day = spark.read.csv('reported-crimes.csv', header = True).withColumn('Date', to_timestamp(col('Date'), 'MM/dd/yyyy hh:mm:ss a')).filter(col('Date') == lit('2018-11-12'))"
      ],
      "metadata": {
        "id": "VBByp92-Y51O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TQNPilURY5yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with dates"
      ],
      "metadata": {
        "id": "bz7XAbb3JRLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ni8ip4bUMQJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from pyspark.sql import functions\n",
        "from pyspark.sql.functions import to_date, to_timestamp, lit"
      ],
      "metadata": {
        "id": "8AcJAJ5PY5sF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame([('2019-12-25 13:30:00',)],['Christmas'])"
      ],
      "metadata": {
        "id": "7KgtwwlSY5pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "dAHGe7opY5l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(to_date(col('Christmas'),'yyyy-MM-dd HH:mm:ss'), to_timestamp(col('Christmas'),'yyyy-MM-dd HH:mm:ss')).show()\n"
      ],
      "metadata": {
        "id": "Ee-ytuRBY5i5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_gmqxyPGY5fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dMS1qwGpY5cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HgmtR6AFY5Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3tFS3XxWY5Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kI2Fj6cLY5PZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}